# âœ‹ CNN Sign Language Alphabet Classifier

**Reconnaissance des lettres de lâ€™alphabet en langue des signes (ASL) Ã  partir dâ€™images avec RÃ©seaux de Neurones Convolutifs**


## ğŸ“Œ Description du Projet

Ce projet consiste Ã  dÃ©velopper un **modÃ¨le CNN de Deep Learning** capable de reconnaÃ®tre les lettres de lâ€™alphabet de la langue des signes amÃ©ricaine (ASL).

Il sâ€™appuie sur le dataset **Sign Language MNIST** (format 28Ã—28 pixels), et inclut :

* PrÃ©traitement avancÃ© des donnÃ©es
* RÃ©Ã©quilibrage des classes (SMOTE)
* Construction dâ€™un CNN efficace
* Recherche dâ€™hyperparamÃ¨tres (GridSearchCV + SciKeras)
* Augmentation dâ€™images
* Comparaison avec un modÃ¨le prÃ©-entraÃ®nÃ© (VGG16)
* Test sur des images capturÃ©es manuellement


## ğŸ“‚ Dataset

Dataset : **Sign Language MNIST**
Format : 28Ã—28 pixels en niveaux de gris
Classes : 24 lettres (J et Z exclues)

### ğŸ“„ Colonnes

* `label` : numÃ©ro associÃ© Ã  la lettre
* `pixel1` â†’ `pixel784` : intensitÃ© des pixels


## ğŸ§¹ PrÃ©traitement des DonnÃ©es

### âœ”ï¸ Nettoyage & Structuration

* Reshape en format image 28Ã—28Ã—1
* Normalisation des pixels `0â€“1`
* Split train / validation / test

### âœ”ï¸ RÃ©Ã©quilibrage avec SMOTE

Les classes Ã©taient lÃ©gÃ¨rement dÃ©sÃ©quilibrÃ©es.
Application de **SMOTE** :

```python
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)
```


## ğŸ§  ModÃ¨le CNN

### ğŸ—ï¸ Architecture

* 3 blocs **Conv2D + MaxPooling**
* **Dropout** pour limiter lâ€™overfitting
* Dense(128) + Dense(64)
* Sortie : Softmax(25)

### ğŸ“ˆ RÃ©sultats

**Accuracy Test (sans augmentation)** : `97.12%`
**Accuracy Test (avec augmentation)** : `97.65%` âœ”ï¸ *meilleure version*


## ğŸ” Recherche dâ€™HyperparamÃ¨tres

Utilisation de **GridSearchCV + SciKeras** :

ParamÃ¨tres testÃ©s :

* `activation`: *relu, sigmoid*
* `optimizer`: *adam, rmsprop*
* `nb_units`: *64, 128*

Meilleurs paramÃ¨tres retenus :

```python
{'activation': 'relu', 'optimizer': 'adam', 'nb_units': 128}
```

âš ï¸ Score CV faible (â‰ˆ0.36) car GridSearch nâ€™entraÃ®ne quâ€™un epoch â†’ modÃ¨le final plus performant.


## ğŸ‹ï¸ Augmentation dâ€™Images

Techniques utilisÃ©es :

* Flip horizontal
* Rotation lÃ©gÃ¨re
* Zoom
* Translation

â†’ AmÃ©lioration mesurable du score de test.


## ğŸ” Test sur Images RÃ©elles

Utilisation dâ€™images personnelles (28Ã—28, grayscale).
Pipeline :

* Chargement
* Redimensionnement
* Normalisation
* PrÃ©diction avec `best_model.keras`

Exemple :

```python
predictions = model.predict(sign_images)
```


## ğŸ§ª ModÃ¨le PrÃ©-EntraÃ®nÃ© : VGG16

### Pourquoi ?

Comparer un CNN simple Ã  un modÃ¨le trÃ¨s profond.

### Adaptations

* Convertir images grayscale â†’ RGB
* Redimensionner 28Ã—28 â†’ 32Ã—32
* Geler les poids du backbone
* Ajouter couches Dense

### RÃ©sultats

**Accuracy Test VGG16** : `93.48%`
â†’ Moins performant que le CNN sur-mesure (dataset simple + petite rÃ©solution).


## ğŸš€ Technologies UtilisÃ©es

* Python 3.x
* TensorFlow / Keras
* SciKit-Learn
* SciKeras
* Pandas / NumPy
* Matplotlib / Seaborn


## â–¶ï¸ Lancer le Projet

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/username/sign-language-cnn.git
cd sign-language-cnn
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. EntraÃ®ner le modÃ¨le

```bash
python train_cnn.py
```

### 4. Tester une image

```bash
python predict.py --image ./images/A.png
```


## ğŸ“Š AmÃ©liorations Possibles

* Ajout de J et Z avec modÃ¨les sÃ©quentiels (RNN + CNN)
* Utilisation de modÃ¨les modernes (EfficientNet, MobileNetV3)
* Portage sur mobile (TensorFlow Lite)
* Interface Streamlit pour tester les signes en direct
* Mode "vidÃ©o" avec reconnaissance continue


## ğŸ‘¤ Auteur

**Alex Alkhatib**
Projet Deep Learning â€” Reconnaissance ASL


## ğŸ“„ Licence
MIT License
Copyright (c) 2025 Alex Alkhatib
